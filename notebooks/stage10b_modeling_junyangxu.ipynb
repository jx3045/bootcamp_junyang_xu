{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Starter — Stage 10b: Time Series & Classification\n",
    "Fill in the TODOs. Use your own dataset or adapt the synthetic generator below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "np.random.seed(7); sns.set(); plt.rcParams['figure.figsize']=(9,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A: Use Your Own Data (Recommended)\n",
    "Load your data here (ensure a DateTime index for time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load your data\n",
    "# df = pd.read_csv('path/to.csv', parse_dates=['Date'], index_col='Date')\n",
    "RAW = \"../data/raw/sample_data.csv\"\n",
    "df = pd.read_csv(RAW)\n",
    "\n",
    "\n",
    "df['Date'] = pd.date_range(\"2021-01-01\", periods=len(df), freq=\"D\")\n",
    "df = df.set_index(\"Date\")\n",
    "\n",
    "\n",
    "series = df['spend'].copy()\n",
    "\n",
    "\n",
    "series = series.fillna(method='ffill').fillna(0)\n",
    "\n",
    "df['spend'] = series\n",
    "\n",
    "df['ret'] = df['spend'].pct_change().fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create at least two features\n",
    "df['lag_1'] = df['ret'].shift(1)\n",
    "df['roll_mean_5'] = df['ret'].rolling(5).mean().shift(1)\n",
    "df['roll_std_10'] = df['ret'].rolling(10).std().shift(1)\n",
    "\n",
    "# Target: next-step return & up/down\n",
    "df['y_next_ret'] = df['ret'].shift(-1)\n",
    "df['y_up'] = (df['y_next_ret']>0).astype(int)\n",
    "\n",
    "df_feat = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-aware split\n",
    "cut=int(len(df_feat)*0.8)\n",
    "train, test = df_feat.iloc[:cut], df_feat.iloc[cut:]\n",
    "features=['lag_1','roll_mean_5','roll_std_10']\n",
    "\n",
    "X_tr, X_te = train[features], test[features]\n",
    "y_tr_reg, y_te_reg = train['y_next_ret'], test['y_next_ret']\n",
    "y_tr_clf, y_te_clf = train['y_up'], test['y_up']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline + Model (Choose one track below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track 1: Forecasting returns\n",
    "reg = Pipeline([('scaler', StandardScaler()), ('linreg', LinearRegression())])\n",
    "reg.fit(X_tr, y_tr_reg)\n",
    "pred_reg = reg.predict(X_te)\n",
    "\n",
    "mae = mean_absolute_error(y_te_reg, pred_reg)\n",
    "rmse = mean_squared_error(y_te_reg, pred_reg)\n",
    "print(f'Regression MAE={mae:.5f}, RMSE={rmse:.5f}')\n",
    "plt.plot(y_te_reg.index, y_te_reg, label='True')\n",
    "plt.plot(y_te_reg.index, pred_reg, label='Predicted')\n",
    "plt.legend(); plt.title(\"Forecasting Returns (spend): Prediction vs Truth\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track 2: Classification (up/down)\n",
    "clf = Pipeline([('scaler', StandardScaler()), ('logit', LogisticRegression(max_iter=1000))])\n",
    "clf.fit(X_tr, y_tr_clf)\n",
    "pred_clf = clf.predict(X_te)\n",
    "\n",
    "print(classification_report(y_te_clf, pred_clf, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_te_clf, pred_clf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix'); plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2530f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = \"../data/processed/sample_data_timeseries.csv\"\n",
    "df_feat.to_csv(OUT, index=True)\n",
    "print(f\"Processed dataset saved to {OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation (Markdown)\n",
    "- What worked?\n",
    "- Where might assumptions fail?\n",
    "- How would you extend features or model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Notebook\n",
    "Remember to save as `notebooks/modeling_<team>.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41eced",
   "metadata": {},
   "source": [
    "## Stage10b — Time Series & Classification (using own dataset)\n",
    "\n",
    "**Steps:**\n",
    "1. Load `data/raw/sample_data.csv` and set up a DateTime index.\n",
    "2. Handle missing values (`ffill` + `fillna(0)`).\n",
    "3. Compute returns based on `spend` column.\n",
    "4. Engineer features: `lag_1`, `roll_mean_5`, `roll_std_10`.\n",
    "5. Create targets:\n",
    "   - `y_next_ret` (for regression forecast).\n",
    "   - `y_up` (binary up/down for classification).\n",
    "6. Use a time-aware 80/20 split.\n",
    "7. Train both:\n",
    "   - **Regression pipeline** → Linear Regression, RMSE & MAE metrics, prediction vs truth plot.\n",
    "   - **Classification pipeline** → Logistic Regression, classification report & confusion matrix.\n",
    "8. Save the processed dataset to `data/processed/sample_data_timeseries.csv`.\n",
    "\n",
    "**Run method:**\n",
    "- Open `notebooks/stage10b_timeseries.ipynb`.\n",
    "- Run all cells.\n",
    "- Check outputs in notebook and processed dataset in `data/processed/`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
